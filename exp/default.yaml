# The location to save checkpoints. If null, it will be the same location and have the same name as this config file.
logdir: null

model:
# hidden_size: Number of hidden units in GRU cells.
# drop_p: Dropout rate.
# use_bn: Whether to insert BatchNorm in EncoderRNN.
# encoder_layers: EncoderRNN layers.
# decoder_layers: DecoderRNN layers.
    hidden_size: 256
    drop_p: 0.3
    use_bn: true
    encoder_layers: 3
    decoder_layers: 2

train:
# batch_size: Batch size.
# init_lr: Initial learning rate. Note the solver we use is Adam.
# decay_factor: Learning rate decay factor.
# patience: Number of epochs with no improvement after which learning rate will be reduced.
# augmentation: Apply SpecAugment during training or not.
    batch_size: 64
    init_lr: 0.0003
    decay_factor : 0.5
    patience: 5
    augmentation: true
